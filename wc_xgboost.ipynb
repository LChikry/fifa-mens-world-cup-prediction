{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# World Cup Bracket Prediction Model\n",
        "\n",
        "## Overview\n",
        "This notebook implements a dual XGBoost regression model to predict expected goals for international football matches. We then use Poisson-based Monte Carlo simulation to generate full bracket predictions with probability estimates.\n",
        "\n",
        "**Key Approach:**\n",
        "- Predict goals, not outcomes (a 5-0 and 1-0 are both \"wins\" but carry different information)\n",
        "- Use Poisson distribution to model goal scoring (mathematically proven for rare, independent events)\n",
        "- Monte Carlo simulation for robust probability estimates\n",
        "\n",
        "**Data Sources:**\n",
        "- International Football Results (2010+)\n",
        "- FIFA World Rankings\n",
        "- EA Sports FC Player Stats (FIFA 15-24)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-1",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from scipy.stats import poisson\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import joblib\n",
        "import json\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# --- Google Colab / Google Drive Configuration ---\n",
        "# Set to True when running in Google Colab to mount Drive\n",
        "USE_GOOGLE_DRIVE = False\n",
        "\n",
        "# Google Drive paths (customize these to your folder structure)\n",
        "GDRIVE_BASE_PATH = '/content/drive/MyDrive/world-cup-prediction'\n",
        "GDRIVE_DATA_PATH = f'{GDRIVE_BASE_PATH}/data'\n",
        "GDRIVE_MODEL_PATH = f'{GDRIVE_BASE_PATH}/model_artifacts'\n",
        "\n",
        "# Local paths (used when not on Google Drive)\n",
        "LOCAL_DATA_PATH = 'data'\n",
        "LOCAL_MODEL_PATH = 'model_artifacts'\n",
        "\n",
        "# Set active paths based on configuration\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    DATA_PATH = GDRIVE_DATA_PATH\n",
        "    MODEL_PATH = GDRIVE_MODEL_PATH\n",
        "else:\n",
        "    DATA_PATH = LOCAL_DATA_PATH\n",
        "    MODEL_PATH = LOCAL_MODEL_PATH\n",
        "\n",
        "print(\"Libraries loaded successfully\")\n",
        "print(f\"Data path: {DATA_PATH}\")\n",
        "print(f\"Model path: {MODEL_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00018022",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive (only runs if USE_GOOGLE_DRIVE is True)\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        \n",
        "        # Create directories if they don't exist\n",
        "        os.makedirs(GDRIVE_DATA_PATH, exist_ok=True)\n",
        "        os.makedirs(GDRIVE_MODEL_PATH, exist_ok=True)\n",
        "        \n",
        "        print(f\"Google Drive mounted successfully\")\n",
        "        print(f\"Data folder: {GDRIVE_DATA_PATH}\")\n",
        "        print(f\"Model folder: {GDRIVE_MODEL_PATH}\")\n",
        "        \n",
        "        # List files in data directory\n",
        "        if os.path.exists(GDRIVE_DATA_PATH):\n",
        "            files = os.listdir(GDRIVE_DATA_PATH)\n",
        "            if files:\n",
        "                print(f\"Files in data folder: {files}\")\n",
        "            else:\n",
        "                print(\"WARNING: Data folder is empty. Please upload the following files:\")\n",
        "                print(\"  - all_matches.csv\")\n",
        "                print(\"  - fifa_ranking_2024.csv\")\n",
        "                print(\"  - players.csv\")\n",
        "                print(\"  - countries_names.csv\")\n",
        "    except ImportError:\n",
        "        print(\"Not running in Google Colab. Using local paths.\")\n",
        "        USE_GOOGLE_DRIVE = False\n",
        "        DATA_PATH = LOCAL_DATA_PATH\n",
        "        MODEL_PATH = LOCAL_MODEL_PATH\n",
        "else:\n",
        "    print(\"Using local paths (USE_GOOGLE_DRIVE is False)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-2",
      "metadata": {},
      "source": [
        "## 2. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets from configured path (local or Google Drive)\n",
        "matches_df = pd.read_csv(f'{DATA_PATH}/all_matches.csv')\n",
        "rankings_df = pd.read_csv(f'{DATA_PATH}/fifa_ranking_2024.csv')\n",
        "players_df = pd.read_csv(f'{DATA_PATH}/players.csv', low_memory=False)\n",
        "country_names_df = pd.read_csv(f'{DATA_PATH}/countries_names.csv')\n",
        "\n",
        "print(f\"Loaded data from: {DATA_PATH}\")\n",
        "print(f\"Matches: {len(matches_df):,} rows\")\n",
        "print(f\"Rankings: {len(rankings_df):,} rows\")\n",
        "print(f\"Players: {len(players_df):,} rows\")\n",
        "print(f\"Country names: {len(country_names_df):,} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "preview-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview match data\n",
        "print(\"Matches columns:\", matches_df.columns.tolist())\n",
        "matches_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "filter-2010",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert date columns\n",
        "matches_df['date'] = pd.to_datetime(matches_df['date'])\n",
        "rankings_df['rank_date'] = pd.to_datetime(rankings_df['rank_date'])\n",
        "\n",
        "# Filter matches to 2010+ (modern football era)\n",
        "matches_df = matches_df[matches_df['date'] >= '2010-01-01'].copy()\n",
        "matches_df = matches_df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "# Add year column for easier filtering\n",
        "matches_df['year'] = matches_df['date'].dt.year\n",
        "\n",
        "print(f\"Matches after 2010 filter: {len(matches_df):,}\")\n",
        "print(f\"Date range: {matches_df['date'].min()} to {matches_df['date'].max()}\")\n",
        "print(f\"\\nTournament breakdown:\")\n",
        "print(matches_df['tournament'].value_counts().head(15))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-3",
      "metadata": {},
      "source": [
        "## 3. Country Name Normalization\n",
        "\n",
        "Country names differ across datasets. We need to normalize them to ensure proper merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "country-map",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build country name normalization from the provided mapping file\n",
        "# The countries_names.csv contains original_name -> current_name mappings\n",
        "name_mapping = dict(zip(country_names_df['original_name'], country_names_df['current_name']))\n",
        "\n",
        "# Additional manual mappings for common variations\n",
        "ADDITIONAL_MAPPINGS = {\n",
        "    # FIFA Rankings variations\n",
        "    'USA': 'United States',\n",
        "    'Korea Republic': 'South Korea',\n",
        "    'Korea DPR': 'North Korea',\n",
        "    'IR Iran': 'Iran',\n",
        "    'China PR': 'China',\n",
        "    \"Cote d'Ivoire\": \"Ivory Coast\",\n",
        "    \"Côte d'Ivoire\": \"Ivory Coast\",\n",
        "    'Czechia': 'Czech Republic',\n",
        "    'Congo DR': 'DR Congo',\n",
        "    'Viet Nam': 'Vietnam',\n",
        "    'Russian Federation': 'Russia',\n",
        "    'Türkiye': 'Turkey',\n",
        "    \n",
        "    # EA Sports player nationality variations\n",
        "    'United States of America': 'United States',\n",
        "    'Korea': 'South Korea',\n",
        "    'Republic of Korea': 'South Korea',\n",
        "    'DPR Korea': 'North Korea',\n",
        "    \"People's Republic of China\": 'China',\n",
        "    'Democratic Republic of Congo': 'DR Congo',\n",
        "    \n",
        "    # UK nations\n",
        "    'England': 'England',\n",
        "    'Scotland': 'Scotland',\n",
        "    'Wales': 'Wales',\n",
        "    'Northern Ireland': 'Northern Ireland',\n",
        "    \n",
        "    # Other common variations\n",
        "    'Republic of Ireland': 'Ireland',\n",
        "    'Eswatini': 'Swaziland',\n",
        "    'Timor-Leste': 'East Timor',\n",
        "    'Trinidad & Tobago': 'Trinidad and Tobago',\n",
        "}\n",
        "\n",
        "# Combine mappings\n",
        "name_mapping.update(ADDITIONAL_MAPPINGS)\n",
        "\n",
        "def normalize_country_name(name):\n",
        "    \"\"\"Normalize country name to canonical form.\"\"\"\n",
        "    if pd.isna(name):\n",
        "        return name\n",
        "    name = str(name).strip()\n",
        "    return name_mapping.get(name, name)\n",
        "\n",
        "print(f\"Total name mappings: {len(name_mapping)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "apply-normalization",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply normalization to all datasets\n",
        "matches_df['home_team'] = matches_df['home_team'].apply(normalize_country_name)\n",
        "matches_df['away_team'] = matches_df['away_team'].apply(normalize_country_name)\n",
        "\n",
        "rankings_df['country_full'] = rankings_df['country_full'].apply(normalize_country_name)\n",
        "\n",
        "players_df['nationality_name'] = players_df['nationality_name'].apply(normalize_country_name)\n",
        "\n",
        "# Get unique teams from matches\n",
        "all_teams = set(matches_df['home_team'].unique()) | set(matches_df['away_team'].unique())\n",
        "print(f\"Unique teams in matches: {len(all_teams)}\")\n",
        "\n",
        "# Check player coverage\n",
        "player_countries = set(players_df['nationality_name'].unique())\n",
        "matched_teams = all_teams & player_countries\n",
        "print(f\"Teams with player data: {len(matched_teams)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-4",
      "metadata": {},
      "source": [
        "## 4. Elo Rating Calculation\n",
        "\n",
        "We calculate Elo ratings for all teams based on historical match results. Elo is a powerful predictor of team strength."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "elo-calc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_elo_ratings(matches_df, k=32, initial_elo=1500):\n",
        "    \"\"\"\n",
        "    Calculate Elo ratings for all teams from match history.\n",
        "    Returns a dict of team -> current elo, and adds elo columns to dataframe.\n",
        "    \"\"\"\n",
        "    elo = defaultdict(lambda: initial_elo)\n",
        "    \n",
        "    # Store Elo at time of each match\n",
        "    home_elos = []\n",
        "    away_elos = []\n",
        "    \n",
        "    for _, match in matches_df.iterrows():\n",
        "        home, away = match['home_team'], match['away_team']\n",
        "        home_elo, away_elo = elo[home], elo[away]\n",
        "        \n",
        "        # Store pre-match Elo\n",
        "        home_elos.append(home_elo)\n",
        "        away_elos.append(away_elo)\n",
        "        \n",
        "        # Expected scores\n",
        "        exp_home = 1 / (1 + 10**((away_elo - home_elo) / 400))\n",
        "        exp_away = 1 - exp_home\n",
        "        \n",
        "        # Actual scores (1=win, 0.5=draw, 0=loss)\n",
        "        home_score, away_score = match['home_score'], match['away_score']\n",
        "        if home_score > away_score:\n",
        "            actual_home, actual_away = 1, 0\n",
        "        elif home_score < away_score:\n",
        "            actual_home, actual_away = 0, 1\n",
        "        else:\n",
        "            actual_home, actual_away = 0.5, 0.5\n",
        "        \n",
        "        # Update Elo\n",
        "        elo[home] += k * (actual_home - exp_home)\n",
        "        elo[away] += k * (actual_away - exp_away)\n",
        "    \n",
        "    return dict(elo), home_elos, away_elos\n",
        "\n",
        "# Calculate Elo ratings\n",
        "elo_ratings, home_elos, away_elos = calculate_elo_ratings(matches_df)\n",
        "\n",
        "# Add Elo columns to matches dataframe\n",
        "matches_df['home_elo'] = home_elos\n",
        "matches_df['away_elo'] = away_elos\n",
        "matches_df['elo_diff'] = matches_df['home_elo'] - matches_df['away_elo']\n",
        "\n",
        "print(f\"Calculated Elo for {len(elo_ratings)} teams\")\n",
        "print(\"\\nTop 20 teams by Elo:\")\n",
        "top_teams = sorted(elo_ratings.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "for i, (team, rating) in enumerate(top_teams, 1):\n",
        "    print(f\"{i:2}. {team:25} {rating:.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-5",
      "metadata": {},
      "source": [
        "## 5. Player Aggregation\n",
        "\n",
        "Aggregate player stats by country and year. We use the top 14 players (typical squad selection) and align FIFA version to match year to avoid data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "player-agg",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check FIFA versions available\n",
        "print(\"FIFA versions in dataset:\")\n",
        "print(players_df['fifa_version'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "player-agg-func",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_fifa_version_for_year(match_year):\n",
        "    \"\"\"\n",
        "    Map match year to FIFA version.\n",
        "    FIFA 15 = 2014/2015 season, FIFA 24 = 2023/2024 season\n",
        "    \"\"\"\n",
        "    # FIFA version is roughly match_year - 2000 + 1\n",
        "    # But we need to cap it at available versions\n",
        "    fifa_version = match_year - 2000 + 1\n",
        "    \n",
        "    # Cap to available versions (15-24)\n",
        "    if fifa_version < 15:\n",
        "        return 15  # Use FIFA 15 for older matches\n",
        "    elif fifa_version > 24:\n",
        "        return 24  # Use FIFA 24 for future matches\n",
        "    return fifa_version\n",
        "\n",
        "def aggregate_players_by_country_year(players_df, top_n=14):\n",
        "    \"\"\"\n",
        "    Aggregate player stats by country and FIFA version.\n",
        "    Returns top N players by overall rating for each country/version.\n",
        "    \"\"\"\n",
        "    # Key columns for aggregation\n",
        "    agg_cols = ['overall', 'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic']\n",
        "    \n",
        "    # Filter to valid data\n",
        "    player_data = players_df[['nationality_name', 'fifa_version', 'overall', \n",
        "                               'pace', 'shooting', 'passing', 'dribbling', \n",
        "                               'defending', 'physic', 'player_positions']].copy()\n",
        "    player_data = player_data.dropna(subset=['nationality_name', 'fifa_version', 'overall'])\n",
        "    player_data['fifa_version'] = player_data['fifa_version'].astype(int)\n",
        "    \n",
        "    aggregations = []\n",
        "    \n",
        "    for (country, version), group in player_data.groupby(['nationality_name', 'fifa_version']):\n",
        "        # Get top N players by overall rating\n",
        "        top_players = group.nlargest(top_n, 'overall')\n",
        "        \n",
        "        if len(top_players) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Basic aggregations\n",
        "        agg_dict = {\n",
        "            'country': country,\n",
        "            'fifa_version': version,\n",
        "            'num_players': len(top_players),\n",
        "            'avg_overall': top_players['overall'].mean(),\n",
        "            'max_overall': top_players['overall'].max(),\n",
        "            'avg_pace': top_players['pace'].mean(),\n",
        "            'avg_shooting': top_players['shooting'].mean(),\n",
        "            'avg_passing': top_players['passing'].mean(),\n",
        "            'avg_dribbling': top_players['dribbling'].mean(),\n",
        "            'avg_defending': top_players['defending'].mean(),\n",
        "            'avg_physic': top_players['physic'].mean(),\n",
        "        }\n",
        "        \n",
        "        # Calculate attack/defense averages based on positions\n",
        "        # Attackers: ST, CF, LW, RW, LF, RF, CAM\n",
        "        # Defenders: CB, LB, RB, LWB, RWB, CDM, GK\n",
        "        attackers = top_players[top_players['player_positions'].fillna('').str.contains(\n",
        "            'ST|CF|LW|RW|LF|RF|CAM', case=False)]\n",
        "        defenders = top_players[top_players['player_positions'].fillna('').str.contains(\n",
        "            'CB|LB|RB|LWB|RWB|CDM|GK', case=False)]\n",
        "        \n",
        "        agg_dict['avg_attack_overall'] = attackers['overall'].mean() if len(attackers) > 0 else agg_dict['avg_overall']\n",
        "        agg_dict['avg_defense_overall'] = defenders['overall'].mean() if len(defenders) > 0 else agg_dict['avg_overall']\n",
        "        \n",
        "        aggregations.append(agg_dict)\n",
        "    \n",
        "    return pd.DataFrame(aggregations)\n",
        "\n",
        "# Aggregate player data\n",
        "player_aggregates = aggregate_players_by_country_year(players_df)\n",
        "print(f\"Player aggregates: {len(player_aggregates)} country-version combinations\")\n",
        "player_aggregates.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "player-agg-check",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check coverage for key World Cup teams\n",
        "wc_teams = ['Brazil', 'Argentina', 'France', 'Germany', 'England', 'Spain', 'Netherlands', 'Portugal']\n",
        "\n",
        "print(\"Player data coverage for key teams:\")\n",
        "for team in wc_teams:\n",
        "    team_data = player_aggregates[player_aggregates['country'] == team]\n",
        "    if len(team_data) > 0:\n",
        "        print(f\"{team}: {len(team_data)} versions, avg overall = {team_data['avg_overall'].mean():.1f}\")\n",
        "    else:\n",
        "        print(f\"{team}: NO DATA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-6",
      "metadata": {},
      "source": [
        "## 6. Feature Engineering\n",
        "\n",
        "Create the full feature set by merging Elo ratings, player stats, and calculating recent form features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "form-features",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_form_features(matches_df, team, match_date, n_matches=5):\n",
        "    \"\"\"\n",
        "    Calculate recent form features for a team before a given match date.\n",
        "    Returns goals scored, goals conceded, and win rate from last N matches.\n",
        "    \"\"\"\n",
        "    # Get team's matches before this date\n",
        "    team_home = matches_df[(matches_df['home_team'] == team) & (matches_df['date'] < match_date)]\n",
        "    team_away = matches_df[(matches_df['away_team'] == team) & (matches_df['date'] < match_date)]\n",
        "    \n",
        "    # Combine and get last N matches\n",
        "    home_results = team_home[['date', 'home_score', 'away_score']].copy()\n",
        "    home_results.columns = ['date', 'goals_for', 'goals_against']\n",
        "    \n",
        "    away_results = team_away[['date', 'away_score', 'home_score']].copy()\n",
        "    away_results.columns = ['date', 'goals_for', 'goals_against']\n",
        "    \n",
        "    all_results = pd.concat([home_results, away_results]).sort_values('date', ascending=False)\n",
        "    recent = all_results.head(n_matches)\n",
        "    \n",
        "    if len(recent) == 0:\n",
        "        return 1.5, 1.5, 0.33  # Default values\n",
        "    \n",
        "    avg_scored = recent['goals_for'].mean()\n",
        "    avg_conceded = recent['goals_against'].mean()\n",
        "    \n",
        "    wins = (recent['goals_for'] > recent['goals_against']).sum()\n",
        "    win_rate = wins / len(recent)\n",
        "    \n",
        "    return avg_scored, avg_conceded, win_rate\n",
        "\n",
        "# Test form calculation\n",
        "test_date = pd.Timestamp('2022-11-20')\n",
        "test_team = 'Brazil'\n",
        "scored, conceded, win_rate = calculate_form_features(matches_df, test_team, test_date)\n",
        "print(f\"{test_team} form before {test_date.date()}:\")\n",
        "print(f\"  Avg goals scored: {scored:.2f}\")\n",
        "print(f\"  Avg goals conceded: {conceded:.2f}\")\n",
        "print(f\"  Win rate: {win_rate:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "build-features",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_feature_dataset(matches_df, player_aggregates, elo_ratings_history=None):\n",
        "    \"\"\"\n",
        "    Build the full feature dataset for training.\n",
        "    \"\"\"\n",
        "    features_list = []\n",
        "    \n",
        "    for idx, match in matches_df.iterrows():\n",
        "        home_team = match['home_team']\n",
        "        away_team = match['away_team']\n",
        "        match_date = match['date']\n",
        "        match_year = match['year']\n",
        "        \n",
        "        # Get FIFA version for this year\n",
        "        fifa_version = get_fifa_version_for_year(match_year)\n",
        "        \n",
        "        # Get player aggregates for each team\n",
        "        home_players = player_aggregates[\n",
        "            (player_aggregates['country'] == home_team) & \n",
        "            (player_aggregates['fifa_version'] == fifa_version)\n",
        "        ]\n",
        "        away_players = player_aggregates[\n",
        "            (player_aggregates['country'] == away_team) & \n",
        "            (player_aggregates['fifa_version'] == fifa_version)\n",
        "        ]\n",
        "        \n",
        "        # Skip if no player data for either team\n",
        "        if len(home_players) == 0 or len(away_players) == 0:\n",
        "            continue\n",
        "        \n",
        "        home_players = home_players.iloc[0]\n",
        "        away_players = away_players.iloc[0]\n",
        "        \n",
        "        # Calculate form features (expensive, so we'll sample for training)\n",
        "        home_scored, home_conceded, home_win_rate = calculate_form_features(\n",
        "            matches_df, home_team, match_date)\n",
        "        away_scored, away_conceded, away_win_rate = calculate_form_features(\n",
        "            matches_df, away_team, match_date)\n",
        "        \n",
        "        # Build feature dict\n",
        "        features = {\n",
        "            # Elo features\n",
        "            'home_elo': match['home_elo'],\n",
        "            'away_elo': match['away_elo'],\n",
        "            'elo_diff': match['elo_diff'],\n",
        "            \n",
        "            # Player aggregate features - Home\n",
        "            'home_avg_overall': home_players['avg_overall'],\n",
        "            'home_max_overall': home_players['max_overall'],\n",
        "            'home_avg_attack': home_players['avg_attack_overall'],\n",
        "            'home_avg_defense': home_players['avg_defense_overall'],\n",
        "            'home_avg_pace': home_players['avg_pace'],\n",
        "            'home_avg_shooting': home_players['avg_shooting'],\n",
        "            'home_avg_passing': home_players['avg_passing'],\n",
        "            \n",
        "            # Player aggregate features - Away\n",
        "            'away_avg_overall': away_players['avg_overall'],\n",
        "            'away_max_overall': away_players['max_overall'],\n",
        "            'away_avg_attack': away_players['avg_attack_overall'],\n",
        "            'away_avg_defense': away_players['avg_defense_overall'],\n",
        "            'away_avg_pace': away_players['avg_pace'],\n",
        "            'away_avg_shooting': away_players['avg_shooting'],\n",
        "            'away_avg_passing': away_players['avg_passing'],\n",
        "            \n",
        "            # Diff features\n",
        "            'overall_diff': home_players['avg_overall'] - away_players['avg_overall'],\n",
        "            'attack_diff': home_players['avg_attack_overall'] - away_players['avg_attack_overall'],\n",
        "            'defense_diff': home_players['avg_defense_overall'] - away_players['avg_defense_overall'],\n",
        "            \n",
        "            # Form features\n",
        "            'home_form_scored': home_scored,\n",
        "            'home_form_conceded': home_conceded,\n",
        "            'home_form_win_rate': home_win_rate,\n",
        "            'away_form_scored': away_scored,\n",
        "            'away_form_conceded': away_conceded,\n",
        "            'away_form_win_rate': away_win_rate,\n",
        "            \n",
        "            # Match context\n",
        "            'is_neutral': 1 if match['neutral'] else 0,\n",
        "            'is_world_cup': 1 if 'FIFA World Cup' in str(match['tournament']) else 0,\n",
        "            'is_continental': 1 if any(x in str(match['tournament']) for x in \n",
        "                                       ['UEFA Euro', 'Copa America', 'Africa Cup', 'AFC Asian Cup']) else 0,\n",
        "            \n",
        "            # Targets\n",
        "            'home_goals': match['home_score'],\n",
        "            'away_goals': match['away_score'],\n",
        "            \n",
        "            # Metadata (for analysis, not training)\n",
        "            '_home_team': home_team,\n",
        "            '_away_team': away_team,\n",
        "            '_date': match_date,\n",
        "            '_tournament': match['tournament'],\n",
        "        }\n",
        "        \n",
        "        features_list.append(features)\n",
        "    \n",
        "    return pd.DataFrame(features_list)\n",
        "\n",
        "# Build feature dataset (this takes a few minutes)\n",
        "print(\"Building feature dataset... (this may take a few minutes)\")\n",
        "feature_df = build_feature_dataset(matches_df, player_aggregates)\n",
        "print(f\"\\nFeature dataset: {len(feature_df)} matches with complete features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feature-summary",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of feature dataset\n",
        "print(\"Feature dataset summary:\")\n",
        "print(f\"Shape: {feature_df.shape}\")\n",
        "print(f\"\\nDate range: {feature_df['_date'].min()} to {feature_df['_date'].max()}\")\n",
        "print(f\"\\nWorld Cup matches: {feature_df['is_world_cup'].sum()}\")\n",
        "\n",
        "# Check for missing values\n",
        "feature_cols = [c for c in feature_df.columns if not c.startswith('_') and c not in ['home_goals', 'away_goals']]\n",
        "print(f\"\\nMissing values:\")\n",
        "missing = feature_df[feature_cols].isnull().sum()\n",
        "print(missing[missing > 0] if missing.sum() > 0 else \"None\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-7",
      "metadata": {},
      "source": [
        "## 7. Model Training\n",
        "\n",
        "Train dual XGBoost regressors: one for home team goals, one for away team goals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train-split",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and targets\n",
        "feature_cols = [c for c in feature_df.columns if not c.startswith('_') and c not in ['home_goals', 'away_goals']]\n",
        "\n",
        "X = feature_df[feature_cols].copy()\n",
        "y_home = feature_df['home_goals'].copy()\n",
        "y_away = feature_df['away_goals'].copy()\n",
        "\n",
        "# Fill any remaining NaN values\n",
        "X = X.fillna(X.mean())\n",
        "\n",
        "print(f\"Features: {len(feature_cols)}\")\n",
        "print(feature_cols)\n",
        "\n",
        "# Split: use 2022+ as test set (including 2022 World Cup)\n",
        "train_mask = feature_df['_date'] < '2022-01-01'\n",
        "test_mask = feature_df['_date'] >= '2022-01-01'\n",
        "\n",
        "X_train, X_test = X[train_mask], X[test_mask]\n",
        "y_home_train, y_home_test = y_home[train_mask], y_home[test_mask]\n",
        "y_away_train, y_away_test = y_away[train_mask], y_away[test_mask]\n",
        "\n",
        "print(f\"\\nTrain set: {len(X_train)} matches\")\n",
        "print(f\"Test set: {len(X_test)} matches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train-models",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Home Goals Model\n",
        "model_home = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_home.fit(X_train, y_home_train, \n",
        "               eval_set=[(X_test, y_home_test)],\n",
        "               verbose=False)\n",
        "\n",
        "print(\"Home Goals Model trained\")\n",
        "\n",
        "# Train Away Goals Model\n",
        "model_away = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_away.fit(X_train, y_away_train,\n",
        "               eval_set=[(X_test, y_away_test)],\n",
        "               verbose=False)\n",
        "\n",
        "print(\"Away Goals Model trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "evaluate-models",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate models\n",
        "y_home_pred = model_home.predict(X_test)\n",
        "y_away_pred = model_away.predict(X_test)\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(\"\\nHome Goals Model:\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_home_test, y_home_pred)):.3f}\")\n",
        "print(f\"  MAE:  {mean_absolute_error(y_home_test, y_home_pred):.3f}\")\n",
        "\n",
        "print(\"\\nAway Goals Model:\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_away_test, y_away_pred)):.3f}\")\n",
        "print(f\"  MAE:  {mean_absolute_error(y_away_test, y_away_pred):.3f}\")\n",
        "\n",
        "# Match outcome accuracy\n",
        "actual_outcomes = np.sign(y_home_test.values - y_away_test.values)\n",
        "pred_outcomes = np.sign(y_home_pred - y_away_pred)\n",
        "outcome_accuracy = (actual_outcomes == pred_outcomes).mean()\n",
        "\n",
        "print(f\"\\nMatch Outcome Accuracy: {outcome_accuracy:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feature-importance",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Home model importance\n",
        "importance_home = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': model_home.feature_importances_\n",
        "}).sort_values('importance', ascending=True).tail(15)\n",
        "\n",
        "axes[0].barh(importance_home['feature'], importance_home['importance'])\n",
        "axes[0].set_title('Home Goals Model - Feature Importance')\n",
        "axes[0].set_xlabel('Importance')\n",
        "\n",
        "# Away model importance\n",
        "importance_away = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': model_away.feature_importances_\n",
        "}).sort_values('importance', ascending=True).tail(15)\n",
        "\n",
        "axes[1].barh(importance_away['feature'], importance_away['importance'])\n",
        "axes[1].set_title('Away Goals Model - Feature Importance')\n",
        "axes[1].set_xlabel('Importance')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-8",
      "metadata": {},
      "source": [
        "## 8. Save Model Artifacts\n",
        "\n",
        "Save all trained components for later inference without retraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "save-artifacts",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model_artifacts(output_dir=None):\n",
        "    \"\"\"Save all components needed for inference.\"\"\"\n",
        "    # Use configured MODEL_PATH if no output_dir specified\n",
        "    if output_dir is None:\n",
        "        output_dir = MODEL_PATH\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # 1. Save trained XGBoost models\n",
        "    joblib.dump(model_home, f'{output_dir}/model_home_goals.joblib')\n",
        "    joblib.dump(model_away, f'{output_dir}/model_away_goals.joblib')\n",
        "    \n",
        "    # 2. Save current Elo ratings\n",
        "    with open(f'{output_dir}/elo_ratings.json', 'w') as f:\n",
        "        json.dump(elo_ratings, f, indent=2)\n",
        "    \n",
        "    # 3. Save player aggregates (latest version for each country)\n",
        "    latest_players = player_aggregates[player_aggregates['fifa_version'] == 24].copy()\n",
        "    latest_players.to_csv(f'{output_dir}/player_aggregates.csv', index=False)\n",
        "    \n",
        "    # 4. Save country name mapping\n",
        "    with open(f'{output_dir}/country_name_map.json', 'w') as f:\n",
        "        json.dump(name_mapping, f, indent=2)\n",
        "    \n",
        "    # 5. Save feature column order\n",
        "    with open(f'{output_dir}/feature_columns.json', 'w') as f:\n",
        "        json.dump(feature_cols, f)\n",
        "    \n",
        "    # 6. Save recent form stats\n",
        "    recent_form = {}\n",
        "    for team in elo_ratings.keys():\n",
        "        scored, conceded, win_rate = calculate_form_features(\n",
        "            matches_df, team, matches_df['date'].max() + pd.Timedelta(days=1))\n",
        "        recent_form[team] = {\n",
        "            'avg_scored': scored,\n",
        "            'avg_conceded': conceded,\n",
        "            'win_rate': win_rate\n",
        "        }\n",
        "    with open(f'{output_dir}/recent_form.json', 'w') as f:\n",
        "        json.dump(recent_form, f, indent=2)\n",
        "    \n",
        "    print(f\"All artifacts saved to {output_dir}\")\n",
        "    if USE_GOOGLE_DRIVE:\n",
        "        print(\"Models saved to Google Drive - they will persist after runtime disconnects\")\n",
        "    print(f\"Files: {os.listdir(output_dir)}\")\n",
        "\n",
        "save_model_artifacts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-9",
      "metadata": {},
      "source": [
        "## 9. Poisson Match Simulator\n",
        "\n",
        "Use predicted goals as lambda parameter for Poisson distribution. Monte Carlo sampling gives robust probability estimates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "poisson-simulator",
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_match(home_goals_pred, away_goals_pred, n_sims=10000):\n",
        "    \"\"\"\n",
        "    Use predicted goals as lambda parameter for Poisson distribution.\n",
        "    Returns win/draw/loss probabilities.\n",
        "    \"\"\"\n",
        "    # Ensure non-negative lambda values\n",
        "    home_lambda = max(0.1, home_goals_pred)\n",
        "    away_lambda = max(0.1, away_goals_pred)\n",
        "    \n",
        "    # Simulate goals using Poisson distribution\n",
        "    home_goals = poisson.rvs(mu=home_lambda, size=n_sims)\n",
        "    away_goals = poisson.rvs(mu=away_lambda, size=n_sims)\n",
        "    \n",
        "    # Calculate probabilities\n",
        "    home_wins = (home_goals > away_goals).mean()\n",
        "    draws = (home_goals == away_goals).mean()\n",
        "    away_wins = (home_goals < away_goals).mean()\n",
        "    \n",
        "    return {\n",
        "        'home_win_prob': home_wins,\n",
        "        'draw_prob': draws,\n",
        "        'away_win_prob': away_wins,\n",
        "        'expected_home_goals': home_goals_pred,\n",
        "        'expected_away_goals': away_goals_pred,\n",
        "        'simulated_home_goals': home_goals,\n",
        "        'simulated_away_goals': away_goals\n",
        "    }\n",
        "\n",
        "def predict_match(home_team, away_team, model_home, model_away, \n",
        "                  player_aggregates, elo_ratings, recent_form,\n",
        "                  is_neutral=True, is_world_cup=True, n_sims=10000):\n",
        "    \"\"\"\n",
        "    Predict a match between two teams with full probability distribution.\n",
        "    \"\"\"\n",
        "    # Get latest FIFA version\n",
        "    fifa_version = 24\n",
        "    \n",
        "    # Get player data\n",
        "    home_players = player_aggregates[\n",
        "        (player_aggregates['country'] == home_team) & \n",
        "        (player_aggregates['fifa_version'] == fifa_version)\n",
        "    ]\n",
        "    away_players = player_aggregates[\n",
        "        (player_aggregates['country'] == away_team) & \n",
        "        (player_aggregates['fifa_version'] == fifa_version)\n",
        "    ]\n",
        "    \n",
        "    if len(home_players) == 0 or len(away_players) == 0:\n",
        "        print(f\"Warning: Missing player data for {home_team} or {away_team}\")\n",
        "        return None\n",
        "    \n",
        "    home_players = home_players.iloc[0]\n",
        "    away_players = away_players.iloc[0]\n",
        "    \n",
        "    # Get Elo ratings\n",
        "    home_elo = elo_ratings.get(home_team, 1500)\n",
        "    away_elo = elo_ratings.get(away_team, 1500)\n",
        "    \n",
        "    # Get form data\n",
        "    home_form = recent_form.get(home_team, {'avg_scored': 1.5, 'avg_conceded': 1.5, 'win_rate': 0.33})\n",
        "    away_form = recent_form.get(away_team, {'avg_scored': 1.5, 'avg_conceded': 1.5, 'win_rate': 0.33})\n",
        "    \n",
        "    # Build feature vector\n",
        "    features = pd.DataFrame([{\n",
        "        'home_elo': home_elo,\n",
        "        'away_elo': away_elo,\n",
        "        'elo_diff': home_elo - away_elo,\n",
        "        'home_avg_overall': home_players['avg_overall'],\n",
        "        'home_max_overall': home_players['max_overall'],\n",
        "        'home_avg_attack': home_players['avg_attack_overall'],\n",
        "        'home_avg_defense': home_players['avg_defense_overall'],\n",
        "        'home_avg_pace': home_players['avg_pace'],\n",
        "        'home_avg_shooting': home_players['avg_shooting'],\n",
        "        'home_avg_passing': home_players['avg_passing'],\n",
        "        'away_avg_overall': away_players['avg_overall'],\n",
        "        'away_max_overall': away_players['max_overall'],\n",
        "        'away_avg_attack': away_players['avg_attack_overall'],\n",
        "        'away_avg_defense': away_players['avg_defense_overall'],\n",
        "        'away_avg_pace': away_players['avg_pace'],\n",
        "        'away_avg_shooting': away_players['avg_shooting'],\n",
        "        'away_avg_passing': away_players['avg_passing'],\n",
        "        'overall_diff': home_players['avg_overall'] - away_players['avg_overall'],\n",
        "        'attack_diff': home_players['avg_attack_overall'] - away_players['avg_attack_overall'],\n",
        "        'defense_diff': home_players['avg_defense_overall'] - away_players['avg_defense_overall'],\n",
        "        'home_form_scored': home_form['avg_scored'],\n",
        "        'home_form_conceded': home_form['avg_conceded'],\n",
        "        'home_form_win_rate': home_form['win_rate'],\n",
        "        'away_form_scored': away_form['avg_scored'],\n",
        "        'away_form_conceded': away_form['avg_conceded'],\n",
        "        'away_form_win_rate': away_form['win_rate'],\n",
        "        'is_neutral': 1 if is_neutral else 0,\n",
        "        'is_world_cup': 1 if is_world_cup else 0,\n",
        "        'is_continental': 0,\n",
        "    }])\n",
        "    \n",
        "    # Reorder columns to match training\n",
        "    features = features[feature_cols]\n",
        "    \n",
        "    # Predict goals\n",
        "    home_goals_pred = model_home.predict(features)[0]\n",
        "    away_goals_pred = model_away.predict(features)[0]\n",
        "    \n",
        "    # Simulate match\n",
        "    result = simulate_match(home_goals_pred, away_goals_pred, n_sims)\n",
        "    result['home_team'] = home_team\n",
        "    result['away_team'] = away_team\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"Poisson simulator ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "test-prediction",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load recent form for predictions\n",
        "with open(f'{MODEL_PATH}/recent_form.json', 'r') as f:\n",
        "    recent_form = json.load(f)\n",
        "\n",
        "# Test prediction\n",
        "result = predict_match('Brazil', 'Argentina', model_home, model_away,\n",
        "                       player_aggregates, elo_ratings, recent_form)\n",
        "\n",
        "if result:\n",
        "    print(f\"\\n{result['home_team']} vs {result['away_team']}\")\n",
        "    print(f\"Expected Goals: {result['expected_home_goals']:.2f} - {result['expected_away_goals']:.2f}\")\n",
        "    print(f\"\\nProbabilities:\")\n",
        "    print(f\"  {result['home_team']} wins: {result['home_win_prob']:.1%}\")\n",
        "    print(f\"  Draw:              {result['draw_prob']:.1%}\")\n",
        "    print(f\"  {result['away_team']} wins: {result['away_win_prob']:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-10",
      "metadata": {},
      "source": [
        "## 10. 2022 World Cup Validation\n",
        "\n",
        "Test the model on the 2022 World Cup to assess accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wc22-validation",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get 2022 World Cup matches from our test set\n",
        "wc22_matches = feature_df[\n",
        "    (feature_df['_date'] >= '2022-11-01') & \n",
        "    (feature_df['_date'] <= '2022-12-31') &\n",
        "    (feature_df['is_world_cup'] == 1)\n",
        "].copy()\n",
        "\n",
        "print(f\"2022 World Cup matches in dataset: {len(wc22_matches)}\")\n",
        "\n",
        "if len(wc22_matches) > 0:\n",
        "    # Make predictions\n",
        "    X_wc = wc22_matches[feature_cols]\n",
        "    wc22_matches['pred_home_goals'] = model_home.predict(X_wc)\n",
        "    wc22_matches['pred_away_goals'] = model_away.predict(X_wc)\n",
        "    \n",
        "    # Calculate outcome accuracy\n",
        "    actual = np.sign(wc22_matches['home_goals'] - wc22_matches['away_goals'])\n",
        "    predicted = np.sign(wc22_matches['pred_home_goals'] - wc22_matches['pred_away_goals'])\n",
        "    accuracy = (actual.values == predicted.values).mean()\n",
        "    \n",
        "    print(f\"\\nMatch outcome accuracy: {accuracy:.1%}\")\n",
        "    print(f\"Home goals RMSE: {np.sqrt(mean_squared_error(wc22_matches['home_goals'], wc22_matches['pred_home_goals'])):.3f}\")\n",
        "    print(f\"Away goals RMSE: {np.sqrt(mean_squared_error(wc22_matches['away_goals'], wc22_matches['pred_away_goals'])):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wc22-details",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show detailed predictions vs actuals\n",
        "if len(wc22_matches) > 0:\n",
        "    display_cols = ['_home_team', '_away_team', 'home_goals', 'away_goals', \n",
        "                    'pred_home_goals', 'pred_away_goals']\n",
        "    display_df = wc22_matches[display_cols].copy()\n",
        "    display_df.columns = ['Home', 'Away', 'Actual Home', 'Actual Away', 'Pred Home', 'Pred Away']\n",
        "    display_df['Pred Home'] = display_df['Pred Home'].round(2)\n",
        "    display_df['Pred Away'] = display_df['Pred Away'].round(2)\n",
        "    \n",
        "    # Add result columns\n",
        "    display_df['Actual Result'] = display_df.apply(\n",
        "        lambda r: 'Home' if r['Actual Home'] > r['Actual Away'] \n",
        "        else ('Away' if r['Actual Home'] < r['Actual Away'] else 'Draw'), axis=1)\n",
        "    display_df['Pred Result'] = display_df.apply(\n",
        "        lambda r: 'Home' if r['Pred Home'] > r['Pred Away'] \n",
        "        else ('Away' if r['Pred Home'] < r['Pred Away'] else 'Draw'), axis=1)\n",
        "    display_df['Correct'] = display_df['Actual Result'] == display_df['Pred Result']\n",
        "    \n",
        "    print(\"2022 World Cup Predictions vs Actuals:\")\n",
        "    print(display_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b495fdb8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate 2022 World Cup with actual teams (32-team format)\n",
        "# Load 2022 World Cup groups\n",
        "wc22_json_path = f'{DATA_PATH}/wc22.json' if os.path.exists(f'{DATA_PATH}/wc22.json') else 'wc22.json'\n",
        "with open(wc22_json_path, 'r') as f:\n",
        "    wc22_groups = json.load(f)\n",
        "\n",
        "# Get all 2022 WC teams\n",
        "wc22_teams = []\n",
        "for group, teams in wc22_groups.items():\n",
        "    wc22_teams.extend(teams)\n",
        "\n",
        "# Filter to teams we have data for\n",
        "wc22_teams_available = [t for t in wc22_teams if t in elo_ratings and \n",
        "                        t in player_aggregates[player_aggregates['fifa_version'] == 24]['country'].values]\n",
        "\n",
        "print(f\"2022 World Cup teams with data: {len(wc22_teams_available)}/{len(wc22_teams)}\")\n",
        "print(f\"Teams: {wc22_teams_available}\")\n",
        "\n",
        "# Run 32-team tournament simulation\n",
        "if len(wc22_teams_available) >= 32:\n",
        "    print(\"\\nRunning 2022 World Cup simulation (32-team format, 100 tournaments)...\")\n",
        "    wc22_champions, wc22_finalists, wc22_semifinalists = simulate_tournament(\n",
        "        wc22_teams_available, n_tournament_sims=100, format='32_team'\n",
        "    )\n",
        "    \n",
        "    print(\"\\n2022 World Cup Simulation Results:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"Championship Probability (Top 10):\")\n",
        "    for i, (team, count) in enumerate(wc22_champions.most_common(10), 1):\n",
        "        prob = count / 100 * 100\n",
        "        print(f\"{i:2}. {team:20} {prob:5.1f}%\")\n",
        "    \n",
        "    print(\"\\nActual Result: Argentina won the 2022 World Cup\")\n",
        "else:\n",
        "    print(f\"Not enough teams with data for 32-team simulation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-11",
      "metadata": {},
      "source": [
        "## 11. 2026 World Cup Tournament Simulation\n",
        "\n",
        "Simulate the full 2026 World Cup tournament with bracket predictions.\n",
        "\n",
        "**Tournament Formats Supported:**\n",
        "- **32-team format** (2018, 2022): 8 groups of 4, top 2 advance to Round of 16\n",
        "- **48-team format** (2026): 12 groups of 4, top 2 + 8 best third-place advance to Round of 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wc26-groups",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2026 World Cup will have 48 teams in 12 groups of 4\n",
        "# For now, let's use projected qualified teams based on current rankings\n",
        "# This is a simplified example - actual groups will be drawn later\n",
        "\n",
        "# Top teams likely to qualify (based on Elo ratings and typical qualifiers)\n",
        "WC2026_PROJECTED_TEAMS = [\n",
        "    # CONMEBOL (6-7 spots)\n",
        "    'Brazil', 'Argentina', 'Uruguay', 'Colombia', 'Ecuador', 'Chile',\n",
        "    # UEFA (16 spots)\n",
        "    'France', 'England', 'Spain', 'Germany', 'Netherlands', 'Portugal',\n",
        "    'Belgium', 'Italy', 'Croatia', 'Switzerland', 'Denmark', 'Austria',\n",
        "    'Poland', 'Serbia', 'Ukraine', 'Sweden',\n",
        "    # CONCACAF (6-7 spots including hosts)\n",
        "    'United States', 'Mexico', 'Canada', 'Costa Rica', 'Jamaica', 'Panama',\n",
        "    # AFC (8-9 spots)\n",
        "    'Japan', 'South Korea', 'Iran', 'Australia', 'Saudi Arabia', 'Qatar',\n",
        "    'United Arab Emirates', 'Iraq',\n",
        "    # CAF (9-10 spots)\n",
        "    'Morocco', 'Senegal', 'Nigeria', 'Egypt', 'Cameroon', 'Algeria',\n",
        "    'Tunisia', 'Ivory Coast', 'Ghana', 'Mali',\n",
        "    # OFC (1-2 spots)\n",
        "    'New Zealand',\n",
        "]\n",
        "\n",
        "# Filter to teams we have data for\n",
        "available_teams = set(player_aggregates[player_aggregates['fifa_version'] == 24]['country'].unique())\n",
        "available_teams &= set(elo_ratings.keys())\n",
        "\n",
        "qualified_teams = [t for t in WC2026_PROJECTED_TEAMS if t in available_teams]\n",
        "print(f\"Projected qualified teams with data: {len(qualified_teams)}\")\n",
        "\n",
        "# Need 48 teams, pad with highest Elo teams if needed\n",
        "if len(qualified_teams) < 48:\n",
        "    remaining = sorted(\n",
        "        [(t, elo_ratings[t]) for t in available_teams if t not in qualified_teams],\n",
        "        key=lambda x: x[1], reverse=True\n",
        "    )\n",
        "    qualified_teams.extend([t for t, _ in remaining[:48-len(qualified_teams)]])\n",
        "\n",
        "qualified_teams = qualified_teams[:48]\n",
        "print(f\"Final team count: {len(qualified_teams)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wc26-sim-func",
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_group_stage(groups, model_home, model_away, player_aggregates, \n",
        "                         elo_ratings, recent_form, n_sims=1000):\n",
        "    \"\"\"\n",
        "    Simulate group stage matches and return standings.\n",
        "    \"\"\"\n",
        "    group_results = {}\n",
        "    \n",
        "    for group_name, teams in groups.items():\n",
        "        # Initialize points and goal difference\n",
        "        standings = {team: {'points': 0, 'gd': 0, 'gf': 0, 'wins': 0} for team in teams}\n",
        "        \n",
        "        # Play all group matches (round robin)\n",
        "        for i, team_a in enumerate(teams):\n",
        "            for team_b in teams[i+1:]:\n",
        "                result = predict_match(team_a, team_b, model_home, model_away,\n",
        "                                       player_aggregates, elo_ratings, recent_form,\n",
        "                                       is_neutral=True, is_world_cup=True, n_sims=n_sims)\n",
        "                \n",
        "                if result is None:\n",
        "                    continue\n",
        "                \n",
        "                # Simulate single match outcome from probabilities\n",
        "                rand = np.random.random()\n",
        "                if rand < result['home_win_prob']:\n",
        "                    # team_a wins\n",
        "                    standings[team_a]['points'] += 3\n",
        "                    standings[team_a]['wins'] += 1\n",
        "                    standings[team_a]['gf'] += result['expected_home_goals']\n",
        "                    standings[team_a]['gd'] += result['expected_home_goals'] - result['expected_away_goals']\n",
        "                    standings[team_b]['gf'] += result['expected_away_goals']\n",
        "                    standings[team_b]['gd'] += result['expected_away_goals'] - result['expected_home_goals']\n",
        "                elif rand < result['home_win_prob'] + result['draw_prob']:\n",
        "                    # draw\n",
        "                    standings[team_a]['points'] += 1\n",
        "                    standings[team_b]['points'] += 1\n",
        "                    standings[team_a]['gf'] += result['expected_home_goals']\n",
        "                    standings[team_b]['gf'] += result['expected_away_goals']\n",
        "                else:\n",
        "                    # team_b wins\n",
        "                    standings[team_b]['points'] += 3\n",
        "                    standings[team_b]['wins'] += 1\n",
        "                    standings[team_b]['gf'] += result['expected_away_goals']\n",
        "                    standings[team_b]['gd'] += result['expected_away_goals'] - result['expected_home_goals']\n",
        "                    standings[team_a]['gf'] += result['expected_home_goals']\n",
        "                    standings[team_a]['gd'] += result['expected_home_goals'] - result['expected_away_goals']\n",
        "        \n",
        "        # Sort by points, then goal difference\n",
        "        sorted_teams = sorted(standings.items(), \n",
        "                              key=lambda x: (x[1]['points'], x[1]['gd'], x[1]['gf']), \n",
        "                              reverse=True)\n",
        "        group_results[group_name] = sorted_teams\n",
        "    \n",
        "    return group_results\n",
        "\n",
        "def simulate_knockout_match(team_a, team_b, model_home, model_away, player_aggregates,\n",
        "                            elo_ratings, recent_form, n_sims=1000):\n",
        "    \"\"\"\n",
        "    Simulate a knockout match (no draws allowed).\n",
        "    \"\"\"\n",
        "    result = predict_match(team_a, team_b, model_home, model_away,\n",
        "                           player_aggregates, elo_ratings, recent_form,\n",
        "                           is_neutral=True, is_world_cup=True, n_sims=n_sims)\n",
        "    \n",
        "    if result is None:\n",
        "        # Fallback: use Elo to decide\n",
        "        return team_a if elo_ratings.get(team_a, 1500) > elo_ratings.get(team_b, 1500) else team_b\n",
        "    \n",
        "    # For knockouts, convert draw probability to coin flip\n",
        "    total_win_prob = result['home_win_prob'] + result['away_win_prob']\n",
        "    adj_home_win = result['home_win_prob'] / total_win_prob if total_win_prob > 0 else 0.5\n",
        "    \n",
        "    # Add half of draw probability to each team\n",
        "    adj_home_win = result['home_win_prob'] + result['draw_prob'] / 2\n",
        "    \n",
        "    if np.random.random() < adj_home_win:\n",
        "        return team_a\n",
        "    else:\n",
        "        return team_b\n",
        "\n",
        "print(\"Knockout simulation functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wc26-full-sim",
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_tournament(teams, n_tournament_sims=100, format='48_team'):\n",
        "    \"\"\"\n",
        "    Run full tournament simulation multiple times.\n",
        "    Returns championship frequency for each team.\n",
        "    \n",
        "    Parameters:\n",
        "    - teams: list of team names\n",
        "    - n_tournament_sims: number of tournament simulations to run\n",
        "    - format: '32_team' (8 groups, used in 2018/2022) or '48_team' (12 groups, used in 2026)\n",
        "    \"\"\"\n",
        "    sorted_teams = sorted(teams, key=lambda t: elo_ratings.get(t, 1500), reverse=True)\n",
        "    \n",
        "    # Set format parameters\n",
        "    if format == '32_team':\n",
        "        n_groups = 8\n",
        "        teams_per_group = 4\n",
        "        n_teams = 32\n",
        "        use_third_place = False  # Top 2 from each group = 16 teams -> Round of 16\n",
        "    elif format == '48_team':\n",
        "        n_groups = 12\n",
        "        teams_per_group = 4\n",
        "        n_teams = 48\n",
        "        use_third_place = True  # Top 2 (24) + 8 best third = 32 teams -> Round of 32\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown format: {format}. Use '32_team' or '48_team'\")\n",
        "    \n",
        "    # Validate team count\n",
        "    if len(sorted_teams) < n_teams:\n",
        "        print(f\"Warning: Only {len(sorted_teams)} teams provided, expected {n_teams}. Padding with available teams.\")\n",
        "        sorted_teams = sorted_teams[:n_teams] if len(sorted_teams) >= n_teams else sorted_teams\n",
        "    else:\n",
        "        sorted_teams = sorted_teams[:n_teams]\n",
        "    \n",
        "    champions = Counter()\n",
        "    finalists = Counter()\n",
        "    semifinalists = Counter()\n",
        "    \n",
        "    for sim_num in range(n_tournament_sims):\n",
        "        # Create groups with serpentine seeding\n",
        "        groups = {f'Group {chr(65+i)}': [] for i in range(n_groups)}\n",
        "        for i, team in enumerate(sorted_teams):\n",
        "            pot = i // n_groups\n",
        "            if pot % 2 == 0:\n",
        "                group_idx = i % n_groups\n",
        "            else:\n",
        "                group_idx = (n_groups - 1) - (i % n_groups)\n",
        "            groups[f'Group {chr(65+group_idx)}'].append(team)\n",
        "        \n",
        "        # Simulate group stage\n",
        "        group_results = simulate_group_stage(groups, model_home, model_away,\n",
        "                                             player_aggregates, elo_ratings, recent_form)\n",
        "        \n",
        "        # Determine advancing teams based on format\n",
        "        advancing = []\n",
        "        third_place = []\n",
        "        \n",
        "        for group_name, standings in group_results.items():\n",
        "            advancing.append(standings[0][0])  # Winner\n",
        "            advancing.append(standings[1][0])  # Runner-up\n",
        "            if use_third_place and len(standings) > 2:\n",
        "                third_place.append((standings[2][0], standings[2][1]['points'], standings[2][1]['gd']))\n",
        "        \n",
        "        # Add best third-place teams for 48-team format\n",
        "        if use_third_place:\n",
        "            third_place.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "            advancing.extend([t[0] for t in third_place[:8]])\n",
        "        \n",
        "        # Knockout rounds\n",
        "        np.random.shuffle(advancing)\n",
        "        current_round = advancing\n",
        "        \n",
        "        # For 48-team: R32 -> R16 -> QF -> SF -> F\n",
        "        # For 32-team: R16 -> QF -> SF -> F\n",
        "        round_names = []\n",
        "        if format == '48_team':\n",
        "            round_names = ['Round of 32', 'Round of 16', 'Quarter Finals', 'Semi Finals', 'Final']\n",
        "        else:\n",
        "            round_names = ['Round of 16', 'Quarter Finals', 'Semi Finals', 'Final']\n",
        "        \n",
        "        for round_name in round_names[:-1]:  # All rounds except Final\n",
        "            next_round = []\n",
        "            for i in range(0, len(current_round), 2):\n",
        "                if i+1 < len(current_round):\n",
        "                    winner = simulate_knockout_match(current_round[i], current_round[i+1],\n",
        "                                                     model_home, model_away, player_aggregates,\n",
        "                                                     elo_ratings, recent_form)\n",
        "                    next_round.append(winner)\n",
        "                    \n",
        "                    # Track semifinalists\n",
        "                    if round_name == 'Quarter Finals':\n",
        "                        semifinalists[winner] += 1\n",
        "                    # Track finalists\n",
        "                    if round_name == 'Semi Finals':\n",
        "                        finalists[winner] += 1\n",
        "            \n",
        "            current_round = next_round\n",
        "        \n",
        "        # Final\n",
        "        if len(current_round) >= 2:\n",
        "            champion = simulate_knockout_match(current_round[0], current_round[1],\n",
        "                                               model_home, model_away, player_aggregates,\n",
        "                                               elo_ratings, recent_form)\n",
        "            champions[champion] += 1\n",
        "    \n",
        "    return champions, finalists, semifinalists\n",
        "\n",
        "# Run tournament simulation\n",
        "print(\"Running 2026 World Cup simulation (100 tournaments)...\")\n",
        "print(\"Format: 48 teams, 12 groups\")\n",
        "print(\"This may take a few minutes...\\n\")\n",
        "\n",
        "champions, finalists, semifinalists = simulate_tournament(qualified_teams, n_tournament_sims=100, format='48_team')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wc26-results",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display results\n",
        "n_sims = 100\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"2026 WORLD CUP PREDICTION RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\nChampionship Probability (Top 20):\")\n",
        "print(\"-\" * 40)\n",
        "for i, (team, count) in enumerate(champions.most_common(20), 1):\n",
        "    prob = count / n_sims * 100\n",
        "    bar = '*' * int(prob / 2)\n",
        "    print(f\"{i:2}. {team:20} {prob:5.1f}% {bar}\")\n",
        "\n",
        "print(\"\\n\\nFinalist Probability (Top 15):\")\n",
        "print(\"-\" * 40)\n",
        "for i, (team, count) in enumerate(finalists.most_common(15), 1):\n",
        "    prob = count / n_sims * 100\n",
        "    print(f\"{i:2}. {team:20} {prob:5.1f}%\")\n",
        "\n",
        "print(\"\\n\\nSemifinalist Probability (Top 15):\")\n",
        "print(\"-\" * 40)\n",
        "for i, (team, count) in enumerate(semifinalists.most_common(15), 1):\n",
        "    prob = count / n_sims * 100\n",
        "    print(f\"{i:2}. {team:20} {prob:5.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-12",
      "metadata": {},
      "source": [
        "## 12. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "viz-championship",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Championship probability visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
        "\n",
        "# Top 15 championship probabilities\n",
        "top_15 = champions.most_common(15)\n",
        "teams = [t[0] for t in top_15]\n",
        "probs = [t[1] / n_sims * 100 for t in top_15]\n",
        "\n",
        "colors = plt.cm.Blues(np.linspace(0.3, 0.9, len(teams)))[::-1]\n",
        "axes[0].barh(teams[::-1], probs[::-1], color=colors)\n",
        "axes[0].set_xlabel('Championship Probability (%)')\n",
        "axes[0].set_title('2026 World Cup - Championship Probability')\n",
        "for i, (team, prob) in enumerate(zip(teams[::-1], probs[::-1])):\n",
        "    axes[0].text(prob + 0.5, i, f'{prob:.1f}%', va='center', fontsize=9)\n",
        "\n",
        "# Elo ratings for comparison\n",
        "elo_top = sorted([(t, elo_ratings.get(t, 1500)) for t in qualified_teams], \n",
        "                 key=lambda x: x[1], reverse=True)[:15]\n",
        "elo_teams = [t[0] for t in elo_top]\n",
        "elo_vals = [t[1] for t in elo_top]\n",
        "\n",
        "colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(elo_teams)))[::-1]\n",
        "axes[1].barh(elo_teams[::-1], elo_vals[::-1], color=colors)\n",
        "axes[1].set_xlabel('Elo Rating')\n",
        "axes[1].set_title('Current Elo Ratings (Top 15)')\n",
        "for i, (team, elo) in enumerate(zip(elo_teams[::-1], elo_vals[::-1])):\n",
        "    axes[1].text(elo + 5, i, f'{elo:.0f}', va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "viz_path = f'{MODEL_PATH}/wc2026_predictions.png'\n",
        "plt.savefig(viz_path, dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"\\nVisualization saved to {viz_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "viz-matchups",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample head-to-head predictions for key matchups\n",
        "key_matchups = [\n",
        "    ('Brazil', 'Argentina'),\n",
        "    ('France', 'England'),\n",
        "    ('Germany', 'Spain'),\n",
        "    ('Netherlands', 'Portugal'),\n",
        "    ('United States', 'Mexico'),\n",
        "    ('Brazil', 'France'),\n",
        "]\n",
        "\n",
        "print(\"\\nKey Matchup Predictions:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for home, away in key_matchups:\n",
        "    result = predict_match(home, away, model_home, model_away,\n",
        "                           player_aggregates, elo_ratings, recent_form)\n",
        "    if result:\n",
        "        print(f\"\\n{home} vs {away}\")\n",
        "        print(f\"Expected Score: {result['expected_home_goals']:.1f} - {result['expected_away_goals']:.1f}\")\n",
        "        print(f\"  {home} wins: {result['home_win_prob']:.1%}\")\n",
        "        print(f\"  Draw:        {result['draw_prob']:.1%}\")\n",
        "        print(f\"  {away} wins: {result['away_win_prob']:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "final-summary",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MODEL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nData:\")\n",
        "print(f\"  - Training matches: {len(X_train):,} (2010-2021)\")\n",
        "print(f\"  - Test matches: {len(X_test):,} (2022+)\")\n",
        "print(f\"  - Features: {len(feature_cols)}\")\n",
        "print(f\"  - Teams with Elo: {len(elo_ratings)}\")\n",
        "print(f\"  - Countries with player data: {len(player_aggregates['country'].unique())}\")\n",
        "\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"  - Home Goals RMSE: {np.sqrt(mean_squared_error(y_home_test, y_home_pred)):.3f}\")\n",
        "print(f\"  - Away Goals RMSE: {np.sqrt(mean_squared_error(y_away_test, y_away_pred)):.3f}\")\n",
        "print(f\"  - Match Outcome Accuracy: {outcome_accuracy:.1%}\")\n",
        "\n",
        "print(f\"\\n2026 World Cup Prediction:\")\n",
        "print(f\"  - Favorite: {champions.most_common(1)[0][0]} ({champions.most_common(1)[0][1]/n_sims*100:.1f}%)\")\n",
        "top_3 = champions.most_common(3)\n",
        "print(f\"  - Top 3: {', '.join([f'{t[0]} ({t[1]/n_sims*100:.1f}%)' for t in top_3])}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"Model artifacts saved to: {MODEL_PATH}\")\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    print(\"(Saved to Google Drive - persistent storage)\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
